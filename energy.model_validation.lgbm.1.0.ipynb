{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> LGBM Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r __ipy\n",
    "%store -r __da\n",
    "%store -r __ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper ipython script loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    body {\n",
       "          font-family: Helvetica, Times New Roman, sans-serif;\n",
       "    }\n",
       "    \n",
       "    h1,h2, h3,h4,h5,h6 {\n",
       "        font-family: Rockwell, Times New Roman, sans-serif;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "__ipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Data Analysis tools was loaded\n"
     ]
    }
   ],
   "source": [
    "__da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "__ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_merge(X_train, X_test, settings):\n",
    "    features = generate_ts_features(X_train, 'meter_reading_log1p', 'hour_datetime', settings)\n",
    "    \n",
    "    X_train = X_train.merge(features, how='left', left_on=KEY_NAME, right_on='id')\n",
    "    X_test = X_test.merge(features, how='left', left_on=KEY_NAME, right_on='id')\n",
    "    \n",
    "    return X_train, X_test\n",
    "\n",
    "\n",
    "settings  = load_settings('')\n",
    "train_X, test_X, tsfresh_features = read_features(generate_and_merge, settings, test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 6\n",
    "@telegram_sender(token=TELEGRAM_API_KEY, chat_id=CHAT_ID)\n",
    "def lgbm_cross_validation(params):\n",
    "    seed = 42\n",
    "    \n",
    "    kf = KFold(n_splits=folds)\n",
    "    total_loss = []\n",
    "    \n",
    "    for train_index, val_index in kf.split(full_train_df):\n",
    "        \n",
    "        train_X = full_train_df.loc[train_index, [*feat_cols, 'meter_reading_log1p']].reset_index(drop=True)\n",
    "        val_X = full_train_df.loc[val_index, feat_cols].reset_index(drop=True)\n",
    "        train_y = target.iloc[train_index]\n",
    "        val_y = target.iloc[val_index]\n",
    "        \n",
    "        ###\n",
    "        \n",
    "        train_X, val_X = generate_and_merge(train_X, val_X, settings)\n",
    "        \n",
    "        ###\n",
    "        train_X.drop('meter_reading_log1p', axis=1, inplace=True)\n",
    "        ####\n",
    "        \n",
    "        ####\n",
    "        \n",
    "        lgb_train = lgb.Dataset(train_X, train_y, categorical_feature=categoricals)\n",
    "        lgb_eval = lgb.Dataset(val_X, val_y, categorical_feature=categoricals)\n",
    "        lgbm = lgb.train(params,\n",
    "                    lgb_train,\n",
    "                    num_boost_round=500,\n",
    "                    valid_sets=(lgb_train, lgb_eval),\n",
    "                    early_stopping_rounds=100,\n",
    "                    verbose_eval = 0)\n",
    "        \n",
    "        pred_y = lgbm.predict(val_X)\n",
    "        mse = np.sqrt(mean_squared_error((val_y), (pred_y)))\n",
    "        total_loss.append(mse)\n",
    "\n",
    "    return {'loss': np.mean(total_loss), 'status': STATUS_OK, 'params': params }\n",
    "\n",
    "def optimize_lgbm(max_evals=1000):\n",
    "    space = {\n",
    "        'metric': {'rmse'},\n",
    "        'num_leaves': scope.int(hp.quniform('num_leaves', 30, 150, 1)),\n",
    "        'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "        'min_data_in_leaf': scope.int(hp.qloguniform('min_data_in_leaf', 0, 6, 1)),\n",
    "        'lambda_l1': hp.choice('lambda_l1', [0, hp.loguniform('lambda_l1_positive', -16, 2)]),\n",
    "        'lambda_l2': hp.choice('lambda_l2', [0, hp.loguniform('lambda_l2_positive', -16, 2)]),\n",
    "        'min_child_weight': hp.loguniform('min_child_weight', -16, 5), #also aliases to min_sum_hessian\n",
    "        'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
    "        'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
    "        'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0),\n",
    "    }\n",
    "    \n",
    "    trials = Trials()\n",
    "    best = fmin(fn=lgbm_cross_validation,\n",
    "                space=space,\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=max_evals,\n",
    "                trials=trials,\n",
    "                verbose= 1)\n",
    "\n",
    "    # find the trial with lowest loss value. this is what we consider the best one\n",
    "    idx = np.argmin(trials.losses())\n",
    "    print(idx)\n",
    "\n",
    "    print(trials.trials[idx])\n",
    "    # these should be the training parameters to use to achieve the best score in best trial\n",
    "    params = trials.trials[idx][\"result\"][\"params\"]\n",
    "    \n",
    "    print(params)\n",
    "    return params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

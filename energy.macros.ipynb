{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Macros and shared functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper ipython script loaded\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output, display\n",
    "from IPython.core.debugger import set_trace\n",
    "from knockknock import telegram_sender\n",
    "\n",
    "TELEGRAM_API_KEY  = '966193511:AAH-8JXV6XZHhHgBIN-M7xD6SIFeSBi8-kk'\n",
    "CHAT_ID = 232512362\n",
    "root = 'data/'\n",
    "models  = 'models/'\n",
    "submission = 'submission/'\n",
    "\n",
    "KEY = ['building_id', 'meter', 'site_id']\n",
    "#KEY_NAME = 'building_id__meter__key'\n",
    "\n",
    "\n",
    "print(\"Helper ipython script loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    body {\n",
       "          font-family: Helvetica, Times New Roman, sans-serif;\n",
       "    }\n",
       "    \n",
       "    h1,h2, h3,h4,h5,h6 {\n",
       "        font-family: Rockwell, Times New Roman, sans-serif;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<style>\n",
    "    body {\n",
    "          font-family: Helvetica, Times New Roman, sans-serif;\n",
    "    }\n",
    "    \n",
    "    h1,h2, h3,h4,h5,h6 {\n",
    "        font-family: Rockwell, Times New Roman, sans-serif;\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Data Analysis tools was loaded\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas(desc=\"\")\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from plotly import graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "init_notebook_mode(connected=True)\n",
    "import os\n",
    "import timeit\n",
    "\n",
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "print(\"Basic Data Analysis tools was loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from hyperopt import hp\n",
    "from hyperopt import fmin, tpe, space_eval\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "import math\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tsfresh import extract_features, extract_relevant_features, select_features\n",
    "from tsfresh.feature_extraction import MinimalFCParameters, EfficientFCParameters ,ComprehensiveFCParameters\n",
    "from sklearn.model_selection import KFold, cross_validate, cross_val_predict\n",
    "from tsfresh.utilities.dataframe_functions import make_forecasting_frame, impute\n",
    "\n",
    "from sklearn.model_selection import *\n",
    "import lightgbm as lgb\n",
    "#import xgboost as xgb\n",
    "import joblib\n",
    "\n",
    "def batch_prediction(model, samples, n = 100):\n",
    "    kfold = KFold(n)\n",
    "    agg = []\n",
    "    \n",
    "    for train_index, test_index in tqdm(kfold.split(samples)):\n",
    "        preds = model.predict(samples.loc[test_index, :])\n",
    "        agg += preds.tolist()\n",
    "        \n",
    "    return agg\n",
    "\n",
    "@telegram_sender(token=TELEGRAM_API_KEY, chat_id=CHAT_ID)\n",
    "def create_submission(model, test_data, submission_name, send_submission=False, message=\"Enter model name\"):\n",
    "    preds = batch_prediction(model, test_data)\n",
    "    \n",
    "    submission_df = pd.DataFrame() \n",
    "    submission_df['row_id'] = np.arange(len(preds))\n",
    "    submission_df['meter_reading'] = preds\n",
    "    submission_df.to_csv(submission + submission_name, index=False)\n",
    "   \n",
    "    if send_submission:\n",
    "        !kaggle competitions submit -c ashrae-energy-prediction -f {submission_name} -m {message}\n",
    "\n",
    "        \n",
    "def read_features(generate_and_merge, settings, test=True):\n",
    "    #test_df.to_pickle(root + \"test_features.pkl\")\n",
    "    train_df = pd.read_pickle(root + \"train_features.pkl\")\n",
    "    full_train_df = train_df.drop('timestamp', axis=1)\n",
    "    full_train_df = full_train_df.reset_index(drop=True)\n",
    "    train_X = full_train_df[[*feat_cols, 'meter_reading_log1p']].reset_index(drop=True)\n",
    "    train_y = full_train_df['meter_reading_log1p']\n",
    "    \n",
    "    if test:\n",
    "        test_df = pd.read_pickle(root + \"test_features.pkl\")\n",
    "        test_X.drop('timestamp', axis=1, inplace=True)\n",
    "        test_X = test_df     \n",
    "        train_X, test_X, tsfresh_features = generate_and_merge(train_X, test_X, **settings)\n",
    "    else:\n",
    "        train_X, test_X, tsfresh_features = generate_and_merge(train_X, None, **settings)\n",
    "\n",
    "    train_X.drop('meter_reading_log1p', axis=1, inplace=True)\n",
    "    return train_X, test_X, tsfresh_features        \n",
    "\n",
    "def load_settings(settings_name):\n",
    "    import json\n",
    "    settings = None\n",
    "    try:\n",
    "        with open(models + settings_name, 'r') as json_file:\n",
    "            settings = json.loads(json_file.read())\n",
    "    except:\n",
    "        print(f'Settings file {settings_name} does not exist')\n",
    "        \n",
    "    return settings\n",
    "\n",
    "def ts_features(train1, column_sort, column_value, settings, column_id):\n",
    "    X=extract_features(train1, \n",
    "                     column_id=column_id,\n",
    "                     column_sort=column_sort,\n",
    "                     column_value=column_value,\n",
    "                     default_fc_parameters=settings,\n",
    "                     impute_function= impute,\n",
    "                     disable_progressbar=True,\n",
    "                     show_warnings=True)\n",
    "    return X\n",
    "\n",
    "def generate_ts_features(X_train, y_col_name, time_col, settings, column_id=\"\"):#column_id=KEY_NAME):\n",
    "    start = time.time()\n",
    "    features = ts_features(X_train, time_col, y_col_name, settings, column_id)\n",
    "    features = reduce_mem_usage(features)\n",
    "    X_filtered = features.replace([np.inf, -np.inf, np.nan], 0)\n",
    "    \n",
    "    end = time.time()\n",
    "    print(\"Time\",end - start)\n",
    "    return X_filtered\n",
    "\n",
    "\n",
    "time_cols = ['month_datetime', 'weekofyear_datetime',\n",
    "             'dayofyear_datetime', 'hour_datetime', \n",
    "             'day_week', 'day_month_datetime',\n",
    "             'week_month_datetime']\n",
    "\n",
    "feat_cols = ['building_id', 'meter', 'timestamp', 'meter_reading', 'site_id',\n",
    "       'primary_use', 'square_feet', 'year_built', 'floor_count',\n",
    "       'air_temperature', 'cloud_coverage', 'dew_temperature',\n",
    "       'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction',\n",
    "       'wind_speed', 'age', 'month_datetime', 'weekofyear_datetime',\n",
    "       'dayofyear_datetime', 'hour_datetime', 'day_week', 'day_month_datetime',\n",
    "       'week_month_datetime', 'weekday', 'is_holiday',\n",
    "       'wind_speed_beaufort_scale', 'group']\n",
    "\n",
    "\n",
    "\n",
    "categoricals =  ['building_id', 'meter','site_id',\n",
    "       'primary_use', 'year_built', 'age', 'month_datetime', 'weekofyear_datetime',\n",
    "       'dayofyear_datetime', 'hour_datetime', 'day_week', 'day_month_datetime',\n",
    "       'week_month_datetime', 'group', 'wind_speed_beaufort_scale', 'is_holiday']        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%macro -q __ipy 1 2\n",
    "%macro -q __da 3\n",
    "%macro -q __ml 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored '__ipy' (Macro)\n",
      "Stored '__da' (Macro)\n",
      "Stored '__ml' (Macro)\n"
     ]
    }
   ],
   "source": [
    "%store __ipy\n",
    "%store __da\n",
    "%store __ml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

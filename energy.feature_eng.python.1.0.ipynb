{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% # <center> Feature engineering\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r __ipy\n",
    "%store -r __da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper ipython script loaded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    body {\n",
       "          font-family: Helvetica, Times New Roman, sans-serif;\n",
       "    }\n",
       "    \n",
       "    h1,h2, h3,h4,h5,h6 {\n",
       "        font-family: Rockwell, Times New Roman, sans-serif;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "__ipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Data Analysis tools was loaded\n"
     ]
    }
   ],
   "source": [
    "__da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv(\"data/weather_train.csv\")\n",
    "\n",
    "\n",
    "weather_df['has_nan'] =  weather_df.isnull().progress_apply(lambda x: 1 if np.any(x) else 0, axis=1)\n",
    "weather_df['timestamp'] = pd.to_datetime(weather_df['timestamp'], infer_datetime_format=False)\n",
    "weather_df.fillna(0, inplace=True)\n",
    "weather_df.to_pickle(root + 'weather_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(root + 'train_df.pkl')\n",
    "test_df = pd.read_pickle(root + 'test_df.pkl')\n",
    "\n",
    "train_df = train_df.query('not (building_id <= 104 & meter == 0 & timestamp <= \"2016-05-20\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['age'] = train_df['year_built'].max() - train_df['year_built'] + 1\n",
    "test_df['age'] = test_df['year_built'].max() - test_df['year_built'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import math\n",
    "\n",
    "le = LabelEncoder()\n",
    "train_df['primary_use'] = train_df['primary_use'].astype(str)\n",
    "train_df['primary_use'] = le.fit_transform(train_df['primary_use']).astype(np.int8)\n",
    "\n",
    "test_df['primary_use'] = test_df['primary_use'].astype(str)\n",
    "test_df['primary_use'] = le.fit_transform(test_df['primary_use']).astype(np.int8)\n",
    "\n",
    "train_df['floor_count'] = train_df['floor_count'].fillna(-999).astype(np.int16)\n",
    "test_df['floor_count'] = test_df['floor_count'].fillna(-999).astype(np.int16)\n",
    "\n",
    "train_df['year_built'] = train_df['year_built'].fillna(-999).astype(np.int16)\n",
    "test_df['year_built'] = test_df['year_built'].fillna(-999).astype(np.int16)\n",
    "\n",
    "train_df['age'] = train_df['age'].fillna(-999).astype(np.int16)\n",
    "test_df['age'] = test_df['age'].fillna(-999).astype(np.int16)\n",
    "\n",
    "train_df['cloud_coverage'] = train_df['cloud_coverage'].fillna(-999).astype(np.int16)\n",
    "test_df['cloud_coverage'] = test_df['cloud_coverage'].fillna(-999).astype(np.int16) \n",
    "\n",
    "\n",
    "train_df['month_datetime'] = train_df['timestamp'].dt.month.astype(np.int8)\n",
    "train_df['weekofyear_datetime'] = train_df['timestamp'].dt.weekofyear.astype(np.int8)\n",
    "train_df['dayofyear_datetime'] = train_df['timestamp'].dt.dayofyear.astype(np.int16)\n",
    "    \n",
    "train_df['hour_datetime'] = train_df['timestamp'].dt.hour.astype(np.int8)  \n",
    "train_df['day_week'] = train_df['timestamp'].dt.dayofweek.astype(np.int8)\n",
    "train_df['day_month_datetime'] = train_df['timestamp'].dt.day.astype(np.int8)\n",
    "train_df['week_month_datetime'] = train_df['timestamp'].dt.day/7\n",
    "train_df['week_month_datetime'] = train_df['week_month_datetime'].apply(lambda x: math.ceil(x)).astype(np.int8)\n",
    "    \n",
    "    \n",
    "test_df['month_datetime'] = test_df['timestamp'].dt.month.astype(np.int8)\n",
    "test_df['weekofyear_datetime'] = test_df['timestamp'].dt.weekofyear.astype(np.int8)\n",
    "test_df['dayofyear_datetime'] = test_df['timestamp'].dt.dayofyear.astype(np.int16)\n",
    "    \n",
    "test_df['hour_datetime'] = test_df['timestamp'].dt.hour.astype(np.int8)\n",
    "test_df['day_week'] = test_df['timestamp'].dt.dayofweek.astype(np.int8)\n",
    "test_df['day_month_datetime'] = test_df['timestamp'].dt.day.astype(np.int8)\n",
    "test_df['week_month_datetime'] = test_df['timestamp'].dt.day/7\n",
    "test_df['week_month_datetime'] = test_df['week_month_datetime'].apply(lambda x: math.ceil(x)).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "305f3c668fdc449f9d283b348001e64d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=19869886), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "KEY = ['building_id', 'meter', 'site_id']\n",
    "\n",
    "def to_key(train_df):\n",
    "    le_key = LabelEncoder()\n",
    "    train_df['building_id__meter__key'] = train_df[KEY].progress_apply(\\\n",
    "        lambda x: str(x['building_id']) + \"_\" + str(x['meter']) + \"_\" +   str(x['site_id']), axis=1)\n",
    "    \n",
    "    le_key.fit(train_df['building_id__meter__key'])\n",
    "    train_df['building_id__meter__key'] = le_key.transform(train_df['building_id__meter__key'])\n",
    "    train_df['building_id__meter__key'] = train_df['building_id__meter__key'].astype(np.int32)\n",
    "    return train_df\n",
    "\n",
    "train_df = to_key(train_df)\n",
    "#test_df = to_key(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['meter_reading_log1p'] = np.log1p(train_df['meter_reading'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['building_id', 'meter', 'timestamp', 'meter_reading', 'site_id',\n",
       "       'primary_use', 'square_feet', 'year_built', 'floor_count',\n",
       "       'air_temperature', 'cloud_coverage', 'dew_temperature',\n",
       "       'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction',\n",
       "       'wind_speed', 'age', 'month_datetime', 'weekofyear_datetime',\n",
       "       'dayofyear_datetime', 'hour_datetime', 'day_week', 'day_month_datetime',\n",
       "       'week_month_datetime', 'building_id__meter__key',\n",
       "       'meter_reading_log1p'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = ['building_id', 'meter', 'site_id',\n",
    "       'primary_use', 'square_feet', 'year_built', 'floor_count',\n",
    "       'air_temperature', 'cloud_coverage', 'dew_temperature',\n",
    "       'precip_depth_1_hr', 'sea_level_pressure', 'wind_direction',\n",
    "       'wind_speed', 'age', 'month_datetime', 'weekofyear_datetime',\n",
    "       'dayofyear_datetime', 'hour_datetime', 'day_week', 'day_month_datetime',\n",
    "       'week_month_datetime', 'building_id__meter__key']\n",
    "\n",
    "categoricals =  ['building_id', 'meter','site_id',\n",
    "       'primary_use', 'year_built', 'age', 'month_datetime', 'weekofyear_datetime',\n",
    "       'dayofyear_datetime', 'hour_datetime', 'day_week', 'day_month_datetime',\n",
    "       'week_month_datetime', 'building_id__meter__key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_df = train_df[feat_cols]\n",
    "target = train_df['meter_reading_log1p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import *\n",
    "import lightgbm as lgb\n",
    "\n",
    "def model_train():\n",
    "    params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'objective': 'regression',\n",
    "            'metric': {'rmse'},\n",
    "            'subsample': 0.4,\n",
    "            'subsample_freq': 1,\n",
    "            'learning_rate': 0.3,\n",
    "            'num_leaves': 40,\n",
    "            'feature_fraction': 0.75,\n",
    "            'lambda_l1': 1,\n",
    "            'lambda_l2': 1\n",
    "    }\n",
    "    \n",
    "    folds = 2\n",
    "    seed = 666\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=folds, shuffle=False, random_state=seed)\n",
    "\n",
    "    models = []\n",
    "    for train_index, val_index in tqdm(kf.split(full_train_df, full_train_df['building_id'])):\n",
    "        train_X = full_train_df.iloc[train_index]\n",
    "        val_X = full_train_df.iloc[val_index]\n",
    "        train_y = target.iloc[train_index]\n",
    "        val_y = target.iloc[val_index]\n",
    "        lgb_train = lgb.Dataset(train_X, train_y, categorical_feature=categoricals)\n",
    "        lgb_eval = lgb.Dataset(val_X, val_y, categorical_feature=categoricals)\n",
    "        gbm = lgb.train(params,\n",
    "                    lgb_train,\n",
    "                    num_boost_round=500,\n",
    "                    valid_sets=(lgb_train, lgb_eval),\n",
    "                    early_stopping_rounds=100,\n",
    "                    verbose_eval = 100)\n",
    "        models.append(gbm)        \n",
    "    return models        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8976b6e3f1ec44678b023581e999ce62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.695419\tvalid_1's rmse: 1.30668\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's rmse: 0.821417\tvalid_1's rmse: 1.19296\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.684807\tvalid_1's rmse: 1.76938\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's rmse: 1.15534\tvalid_1's rmse: 1.37261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_cross_validation(params):\n",
    "    folds = 2\n",
    "    seed = 42\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=folds, shuffle=False, random_state=seed)\n",
    "    total_loss = []\n",
    "    \n",
    "    for train_index, val_index in tqdm(kf.split(full_train_df, full_train_df['building_id'])):\n",
    "        train_X = full_train_df.iloc[train_index]\n",
    "        val_X = full_train_df.iloc[val_index]\n",
    "        train_y = target.iloc[train_index]\n",
    "        val_y = target.iloc[val_index]\n",
    "        lgb_train = lgb.Dataset(train_X, train_y, categorical_feature=categoricals)\n",
    "        lgb_eval = lgb.Dataset(val_X, val_y, categorical_feature=categoricals)\n",
    "        lgbm = lgb.train(params,\n",
    "                    lgb_train,\n",
    "                    num_boost_round=500,\n",
    "                    valid_sets=(lgb_train, lgb_eval),\n",
    "                    early_stopping_rounds=100,\n",
    "                    verbose_eval = 100)\n",
    "        \n",
    "        pred_y = lgbm.predict(val_X)\n",
    "        mse = np.sqrt(mean_squared_error((val_y), (pred_y)))\n",
    "        total_loss.append(mse)\n",
    "\n",
    "    return {'loss': np.mean(total_loss), 'status': STATUS_OK, 'params': params }\n",
    "\n",
    "def optimize_lgbm(max_evals=1000):\n",
    "    space = {\n",
    "        'metric': {'rmse'},\n",
    "        'num_leaves': scope.int(hp.quniform('num_leaves', 30, 150, 1)),\n",
    "        'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "        'min_data_in_leaf': scope.int(hp.qloguniform('min_data_in_leaf', 0, 6, 1)),\n",
    "        'lambda_l1': hp.choice('lambda_l1', [0, hp.loguniform('lambda_l1_positive', -16, 2)]),\n",
    "        'lambda_l2': hp.choice('lambda_l2', [0, hp.loguniform('lambda_l2_positive', -16, 2)]),\n",
    "        'min_child_weight': hp.loguniform('min_child_weight', -16, 5), #also aliases to min_sum_hessian\n",
    "        'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
    "        'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
    "        'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0),\n",
    "    }\n",
    "    \n",
    "    trials = Trials()\n",
    "    best = fmin(fn=lgbm_cross_validation,\n",
    "                space=space,\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=max_evals,\n",
    "                trials=trials,\n",
    "                verbose= 1)\n",
    "\n",
    "    # find the trial with lowest loss value. this is what we consider the best one\n",
    "    idx = np.argmin(trials.losses())\n",
    "    print(idx)\n",
    "\n",
    "    print(trials.trials[idx])\n",
    "    # these should be the training parameters to use to achieve the best score in best trial\n",
    "    params = trials.trials[idx][\"result\"][\"params\"]\n",
    "    \n",
    "    print(params)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                                                                | 0/500 [00:00<?, ?it/s, best loss: ?]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11b2b55a4424f38866468836a273c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds                                                                                                                                                                                                              \n",
      "[100]\ttraining's rmse: 0.660048\tvalid_1's rmse: 1.25951                                                                                                                                                                                                                    \n",
      "Early stopping, best iteration is:                                                                                                                                                                                                                                         \n",
      "[55]\ttraining's rmse: 0.741608\tvalid_1's rmse: 1.24183\n",
      "  0%|                                                                                                                                                                                                                                | 0/500 [03:29<?, ?it/s, best loss: ?]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mean_squared_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-109-826e480a8405>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mhyperopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyll\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mhp_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimize_lgbm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mhp_params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-107-e253960d081d>\u001b[0m in \u001b[0;36moptimize_lgbm\u001b[1;34m(max_evals)\u001b[0m\n\u001b[0;32m     46\u001b[0m                 \u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_evals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m                 \u001b[0mtrials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m                 verbose= 1)\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;31m# find the trial with lowest loss value. this is what we consider the best one\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maksym_suprunenko\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[0;32m    401\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m             \u001b[0mshow_progressbar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m         )\n\u001b[0;32m    405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maksym_suprunenko\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(self, fn, space, algo, max_evals, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar)\u001b[0m\n\u001b[0;32m    649\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m             show_progressbar=show_progressbar)\n\u001b[0m\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maksym_suprunenko\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[0;32m    420\u001b[0m                     show_progressbar=show_progressbar)\n\u001b[0;32m    421\u001b[0m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maksym_suprunenko\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maksym_suprunenko\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    239\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m                         \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maksym_suprunenko\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    139\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'job exception: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maksym_suprunenko\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    854\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[1;32m--> 856\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-107-e253960d081d>\u001b[0m in \u001b[0;36mlgbm_cross_validation\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mpred_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpred_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mtotal_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mean_squared_error' is not defined"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"2c2ccd55-084c-4060-a91a-85829c9aef01\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"2c2ccd55-084c-4060-a91a-85829c9aef01\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Hyperopt execution was finished\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%notify -m \"Hyperopt execution was finished\"\n",
    "\n",
    "# Bayessian Optimization\n",
    "from bayes_opt import BayesianOptimization\n",
    "from hyperopt import hp\n",
    "from hyperopt import fmin, tpe, space_eval\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "from hyperopt.pyll import scope \n",
    "\n",
    "hp_params = optimize_lgbm(500)\n",
    "hp_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSFresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings={\n",
    "'standard_deviation': None,\n",
    " 'variance': None,\n",
    " 'skewness': None,\n",
    " 'kurtosis': None,\n",
    " 'absolute_sum_of_changes': None,\n",
    "\n",
    "'last_location_of_maximum': None,\n",
    " 'first_location_of_maximum': None,\n",
    " 'last_location_of_minimum': None,\n",
    "'first_location_of_minimum': None,\n",
    "'count_above_mean': None,\n",
    " 'count_below_mean': None,\n",
    " 'maximum': None,\n",
    " 'minimum': None,\n",
    "\n",
    " 'c3': [{'lag': 100}, {'lag': 2000}, {'lag': 3000},{'lag': 10000}],\n",
    "\n",
    "'number_peaks': [{'n': 1}, {'n': 5},{'n': 100},{'n': 1000}],\n",
    "'fft_coefficient': \n",
    " [{'coeff': 0, 'attr': 'real'},\n",
    "  {'coeff': 1, 'attr': 'real'},\n",
    "  {'coeff': 2, 'attr': 'real'},\n",
    "  {'coeff': 3, 'attr': 'real'},\n",
    "  {'coeff': 4, 'attr': 'real'},\n",
    "\n",
    "  {'coeff': 0, 'attr': 'imag'},\n",
    "  {'coeff': 1, 'attr': 'imag'},\n",
    "  {'coeff': 2, 'attr': 'imag'},\n",
    "  {'coeff': 3, 'attr': 'imag'},\n",
    "  {'coeff': 4, 'attr': 'imag'},\n",
    "  {'coeff': 5, 'attr': 'imag'},\n",
    "\n",
    "  {'coeff': 0, 'attr': 'abs'},\n",
    "  {'coeff': 1, 'attr': 'abs'},\n",
    "  {'coeff': 2, 'attr': 'abs'},\n",
    "  {'coeff': 3, 'attr': 'abs'},\n",
    "  {'coeff': 4, 'attr': 'abs'},\n",
    "  {'coeff': 5, 'attr': 'abs'},\n",
    "\n",
    "  {'coeff': 0, 'attr': 'angle'},\n",
    "  {'coeff': 1, 'attr': 'angle'},\n",
    "  {'coeff': 2, 'attr': 'angle'},\n",
    "  {'coeff': 3, 'attr': 'angle'},\n",
    "  {'coeff': 4, 'attr': 'angle'},\n",
    "  {'coeff': 5, 'attr': 'angle'},\n",
    "],\n",
    " 'agg_linear_trend': [\n",
    "     {'attr': 'rvalue', 'chunk_len': 500, 'f_agg': 'max'},\n",
    "  {'attr': 'rvalue', 'chunk_len': 500, 'f_agg': 'min'},\n",
    "  {'attr': 'rvalue', 'chunk_len': 500, 'f_agg': 'mean'},\n",
    "  {'attr': 'rvalue', 'chunk_len': 500, 'f_agg': 'var'},\n",
    "  {'attr': 'rvalue', 'chunk_len': 1000, 'f_agg': 'max'},\n",
    "  {'attr': 'rvalue', 'chunk_len': 1000, 'f_agg': 'min'},\n",
    "  {'attr': 'rvalue', 'chunk_len': 1000, 'f_agg': 'mean'},\n",
    "  {'attr': 'rvalue', 'chunk_len': 1000, 'f_agg': 'var'},\n",
    "  {'attr': 'rvalue', 'chunk_len': 5000, 'f_agg': 'max'},\n",
    "  {'attr': 'rvalue', 'chunk_len': 5000, 'f_agg': 'min'},\n",
    "  {'attr': 'rvalue', 'chunk_len': 5000, 'f_agg': 'mean'},\n",
    "  {'attr': 'rvalue', 'chunk_len': 5000, 'f_agg': 'var'},\n",
    "  {'attr': 'intercept', 'chunk_len': 500, 'f_agg': 'max'},\n",
    "  {'attr': 'intercept', 'chunk_len': 500, 'f_agg': 'min'},\n",
    "  {'attr': 'intercept', 'chunk_len': 500, 'f_agg': 'mean'},\n",
    "  {'attr': 'intercept', 'chunk_len': 500, 'f_agg': 'var'},\n",
    "  {'attr': 'intercept', 'chunk_len': 1000, 'f_agg': 'max'},\n",
    "  {'attr': 'intercept', 'chunk_len': 1000, 'f_agg': 'min'},\n",
    "  {'attr': 'intercept', 'chunk_len': 1000, 'f_agg': 'mean'},\n",
    "  {'attr': 'intercept', 'chunk_len': 1000, 'f_agg': 'var'},\n",
    "  {'attr': 'intercept', 'chunk_len': 5000, 'f_agg': 'max'},\n",
    "  {'attr': 'intercept', 'chunk_len': 5000, 'f_agg': 'min'},\n",
    "  {'attr': 'intercept', 'chunk_len': 5000, 'f_agg': 'mean'},\n",
    "  {'attr': 'intercept', 'chunk_len': 5000, 'f_agg': 'var'},\n",
    "  {'attr': 'slope', 'chunk_len': 500, 'f_agg': 'max'},\n",
    "  {'attr': 'slope', 'chunk_len': 500, 'f_agg': 'min'},\n",
    "  {'attr': 'slope', 'chunk_len': 500, 'f_agg': 'mean'},\n",
    "  {'attr': 'slope', 'chunk_len': 500, 'f_agg': 'var'},\n",
    "  {'attr': 'slope', 'chunk_len': 1000, 'f_agg': 'max'},\n",
    "  {'attr': 'slope', 'chunk_len': 1000, 'f_agg': 'min'},\n",
    "  {'attr': 'slope', 'chunk_len': 1000, 'f_agg': 'mean'},\n",
    "  {'attr': 'slope', 'chunk_len': 1000, 'f_agg': 'var'},\n",
    "  {'attr': 'slope', 'chunk_len': 5000, 'f_agg': 'max'},\n",
    "  {'attr': 'slope', 'chunk_len': 5000, 'f_agg': 'min'},\n",
    "  {'attr': 'slope', 'chunk_len': 5000, 'f_agg': 'mean'},\n",
    "  {'attr': 'slope', 'chunk_len': 5000, 'f_agg': 'var'},\n",
    "  {'attr': 'stderr', 'chunk_len': 500, 'f_agg': 'max'},\n",
    "  {'attr': 'stderr', 'chunk_len': 500, 'f_agg': 'min'},\n",
    "  {'attr': 'stderr', 'chunk_len': 500, 'f_agg': 'mean'},\n",
    "  {'attr': 'stderr', 'chunk_len': 500, 'f_agg': 'var'},\n",
    "  {'attr': 'stderr', 'chunk_len': 1000, 'f_agg': 'max'},\n",
    "  {'attr': 'stderr', 'chunk_len': 1000, 'f_agg': 'min'},\n",
    "  {'attr': 'stderr', 'chunk_len': 1000, 'f_agg': 'mean'},\n",
    "  {'attr': 'stderr', 'chunk_len': 1000, 'f_agg': 'var'},\n",
    "  {'attr': 'stderr', 'chunk_len': 5000, 'f_agg': 'max'},\n",
    "  {'attr': 'stderr', 'chunk_len': 5000, 'f_agg': 'min'},\n",
    "  {'attr': 'stderr', 'chunk_len': 5000, 'f_agg': 'mean'},\n",
    "  {'attr': 'stderr', 'chunk_len': 5000, 'f_agg': 'var'}],\n",
    " 'index_mass_quantile': [{'q': 0.1},\n",
    "  {'q': 0.2},\n",
    "  {'q': 0.3},\n",
    "  {'q': 0.4},\n",
    "  {'q': 0.6},\n",
    "  {'q': 0.7},\n",
    "  {'q': 0.8},\n",
    "  {'q': 0.9}],\n",
    "\n",
    " 'spkt_welch_density': [{'coeff': 2}, {'coeff': 5}, {'coeff': 8}],\n",
    " 'ar_coefficient': [{'coeff': 0, 'k': 10},\n",
    "  {'coeff': 1, 'k': 10},\n",
    "  {'coeff': 2, 'k': 10},\n",
    "  {'coeff': 3, 'k': 10},\n",
    "  {'coeff': 4, 'k': 10}],\n",
    "\n",
    " 'energy_ratio_by_chunks': [{'num_segments': 10, 'segment_focus': 0},\n",
    "  {'num_segments': 10, 'segment_focus': 1},\n",
    "  {'num_segments': 10, 'segment_focus': 2},\n",
    "  {'num_segments': 10, 'segment_focus': 3},\n",
    "  {'num_segments': 10, 'segment_focus': 4},\n",
    "  {'num_segments': 10, 'segment_focus': 5},\n",
    "  {'num_segments': 10, 'segment_focus': 6},\n",
    "  {'num_segments': 10, 'segment_focus': 7},\n",
    "  {'num_segments': 10, 'segment_focus': 8},\n",
    "  {'num_segments': 10, 'segment_focus': 9}],\n",
    " 'ratio_beyond_r_sigma': [{'r': 0.5},\n",
    "  {'r': 1},\n",
    "  {'r': 1.5},\n",
    "  {'r': 2},\n",
    "  {'r': 2.5},\n",
    "  {'r': 3},\n",
    "  {'r': 5},\n",
    "  {'r': 6},\n",
    "  {'r': 7},\n",
    "  {'r': 10}],\n",
    "'max_langevin_fixed_point': [{'m': 3, 'r': 30}],\n",
    "    'change_quantiles': [{'ql': 0.0, 'qh': 0.2, 'isabs': False, 'f_agg': 'mean'},\n",
    "  {'ql': 0.0, 'qh': 0.2, 'isabs': False, 'f_agg': 'var'},\n",
    "  {'ql': 0.0, 'qh': 0.2, 'isabs': True, 'f_agg': 'mean'},\n",
    "  {'ql': 0.0, 'qh': 0.2, 'isabs': True, 'f_agg': 'var'},\n",
    "  {'ql': 0.0, 'qh': 0.4, 'isabs': False, 'f_agg': 'mean'},\n",
    "  {'ql': 0.0, 'qh': 0.4, 'isabs': False, 'f_agg': 'var'},\n",
    "  {'ql': 0.0, 'qh': 0.4, 'isabs': True, 'f_agg': 'mean'},\n",
    "  {'ql': 0.0, 'qh': 0.4, 'isabs': True, 'f_agg': 'var'},\n",
    "  {'ql': 0.0, 'qh': 0.6, 'isabs': False, 'f_agg': 'mean'},\n",
    "  {'ql': 0.0, 'qh': 0.6, 'isabs': False, 'f_agg': 'var'},\n",
    "  {'ql': 0.0, 'qh': 0.6, 'isabs': True, 'f_agg': 'mean'},\n",
    "  {'ql': 0.0, 'qh': 0.6, 'isabs': True, 'f_agg': 'var'},\n",
    "  {'ql': 0.0, 'qh': 0.8, 'isabs': False, 'f_agg': 'mean'},\n",
    "  {'ql': 0.0, 'qh': 0.8, 'isabs': False, 'f_agg': 'var'},\n",
    "  {'ql': 0.0, 'qh': 0.8, 'isabs': True, 'f_agg': 'mean'},\n",
    "  {'ql': 0.0, 'qh': 0.8, 'isabs': True, 'f_agg': 'var'},\n",
    "  {'ql': 0.0, 'qh': 1.0, 'isabs': False, 'f_agg': 'mean'}]\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from tsfresh import extract_features, extract_relevant_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tsfresh.feature_extraction import MinimalFCParameters, EfficientFCParameters ,ComprehensiveFCParameters\n",
    "from sklearn.model_selection import KFold, cross_validate, cross_val_predict\n",
    "import timeit\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsfresh_time(sett):\n",
    "    for f, param in tqdm(sett.items()):\n",
    "        res.loc[f, \"feature\"] = f\n",
    "        res.loc[f, \"n_samp\"] = n_ts\n",
    "        res.loc[f, \"length\"] = l_ts\n",
    "\n",
    "        fc_dict = {f:param}\n",
    "\n",
    "        t = timeit.timeit(lambda : extract_features(train_t, \n",
    "                         column_id='building_id__meter__key',\n",
    "                         column_sort='timestamp',\n",
    "                         column_value=\"meter_reading\",\n",
    "                         n_jobs=12, \n",
    "                         default_fc_parameters=fc_dict, \n",
    "                         disable_progressbar=True), \n",
    "                          number=n_ti)\n",
    "        n_fs = 1\n",
    "        res.loc[f, \"n_fs\"] = n_fs\n",
    "        res.loc[f, \"t_abs\"] = t * 1.0/n_fs\n",
    "        res.loc[f, \"t_1ts\"] = t*1.0/(n_ts*n_fs)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_features(train1,settings):\n",
    "    X=extract_features(train1, \n",
    "                     column_id='id',\n",
    "                     column_sort='time',\n",
    "                     column_value=\"acoustic_data\",\n",
    "                     default_fc_parameters=settings,\n",
    "                     #impute_function= impute,\n",
    "                     disable_progressbar=True,\n",
    "                     show_warnings=True)\n",
    "    return X\n",
    "\n",
    "\n",
    "for i in progressbar(range(segments), \"Computing: \", 40):  \n",
    "    X1 = pd.DataFrame()\n",
    "    train1=pd.concat([ids,times,train[i * n:(i + 1) *n].reset_index(drop=True)],axis=1)\n",
    "    seg = train[i*n:(i + 1)*n]\n",
    "    y = seg['time_to_failure'].values[-1]\n",
    "    y_tr.loc[i, 'time_to_failure'] = y\n",
    "    \n",
    "    #Features in whole segment\n",
    "    X2=ts_features(train1,peak)\n",
    "    #Features per section 4x37500\n",
    "    for j in range(4):\n",
    "        \n",
    "        X=ts_features(train1[j * parts:(j + 1) *parts],settings).add_prefix('q_' +str(j))\n",
    "        X1=pd.concat([X1,X], axis=1)\n",
    "   \n",
    "    #print(X1.shape)\n",
    "    X_filtered=X_filtered.append(pd.concat([X1,X2], axis=1))\n",
    "    \n",
    "\n",
    "X_filtered=X_filtered.reset_index().drop(['id'], axis=1)\n",
    "\n",
    "print(X_filtered.shape)\n",
    "print(y_tr.shape)\n",
    "del train\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time\",end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_pickle(root+'train.pkl')\n",
    "val.to_pickle(root+'val.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
